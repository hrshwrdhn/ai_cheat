{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_cifar_gpu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+G+EENPhZFOyUYDFLHIax",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hrshwrdhn/ai_cheat/blob/main/assignment_cifar_gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMd_tAD8UpJL"
      },
      "source": [
        "## go to runtime>> change runtime type >> select GPU   if you are using google colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8TXgfMDKpnw"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqHVugzFK329"
      },
      "source": [
        "dataset = CIFAR10(root='data/', download=True, transform=ToTensor())\n",
        "test_dataset = CIFAR10(root='data/', train=False, transform=ToTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvqkNgnXLDD0"
      },
      "source": [
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTOT7CrQLHRk"
      },
      "source": [
        "dataset[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMMh0aOZLUIa"
      },
      "source": [
        " ## Q1 . How many images does the training dataset contain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGZmQiG_LKSq"
      },
      "source": [
        "# write here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEtBOuAPLcN2"
      },
      "source": [
        "ans = 50000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-hbDlDSLjib"
      },
      "source": [
        "## Q2: How many images does the test dataset contain?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOdJV3yfLazW"
      },
      "source": [
        "# write here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0ORhdbNLxhs"
      },
      "source": [
        "## Q3: How many output classes does the dataset contain? Can you list them?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UafIVBLzLpLa"
      },
      "source": [
        "# write here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuDVzVBsL7IS"
      },
      "source": [
        "ans = (10,\n",
        " ['airplane',\n",
        "  'automobile',\n",
        "  'bird',\n",
        "  'cat',\n",
        "  'deer',\n",
        "  'dog',\n",
        "  'frog',\n",
        "  'horse',\n",
        "  'ship',\n",
        "  'truck'])\n",
        "\n",
        "hint: use `dataset.classes`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utL4VWidMIS5"
      },
      "source": [
        "## Q4:  What is the shape of an image tensor from the dataset?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7xfHys1L5xm"
      },
      "source": [
        "# write here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTmN0UC8MSKs"
      },
      "source": [
        "ans: torch.Size([3, 32, 32])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y43FlkDjMf_7"
      },
      "source": [
        "## note\n",
        " this dataset consists of 3-channel color images (RGB). Let us look at a sample image from the dataset. matplotlib expects channels to be the last dimension of the image tensors (whereas in PyTorch they are the first dimension), so we'll the .permute tensor method to shift channels to the last dimension. Let's also print the label for the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfYkGK1FMNx1"
      },
      "source": [
        "img, label = dataset[3]\n",
        "plt.imshow(img.permute((1, 2, 0)))\n",
        "print('Label (numeric):', label)\n",
        "print('Label (textual):', classes[label])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxkMUt99Mx_x"
      },
      "source": [
        "## Q5: Can you determine the number of images belonging to each class?\n",
        "\n",
        "Hint: Loop through the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2i0CCGPTMmvi"
      },
      "source": [
        "# write here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzirYu6BNRoN"
      },
      "source": [
        "answer\n",
        "1. Number of images belonging to airplane is 5000\n",
        "2. Number of images belonging to automobile is 5000\n",
        "3. Number of images belonging to bird is 5000\n",
        "4. Number of images belonging to cat is 5000\n",
        "5. Number of images belonging to deer is 5000\n",
        "6. Number of images belonging to dog is 5000\n",
        "7. Number of images belonging to frog is 5000\n",
        "8. Number of images belonging to horse is 5000\n",
        "9. Number of images belonging to ship is 5000\n",
        "10. Number of images belonging to truck is 5000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h95C6qKPNRsa"
      },
      "source": [
        "# Preparing the data for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuvXUFwdNRwp"
      },
      "source": [
        " use a validation set with 5000 images (10% of the dataset). To ensure we get the same validation set each time, we'll set PyTorch's random number generator to a seed value of 43."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCjYKSsuNuEd"
      },
      "source": [
        "torch.manual_seed(43)\n",
        "val_size = 5000\n",
        "train_size = len(dataset) - val_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fzg__YhcNzMw"
      },
      "source": [
        "## Q6: use the random_split method to create the training & validation sets\n",
        "\n",
        "create train_ds, val_ds using function `random_split`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hF_rWB4Ny6i"
      },
      "source": [
        "# write here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPdUTCVcOOnc"
      },
      "source": [
        "# run this line to verify \n",
        "len(train_ds), len(val_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXTSjpG1N-7l"
      },
      "source": [
        "ans: (45000, 5000)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hJDwuZGNDit"
      },
      "source": [
        "batch_size=128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBgU8-y5OeFv"
      },
      "source": [
        "# Q7:   create data loaders to load the data in batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMdqb-Q6ThVr"
      },
      "source": [
        "train_loader =  # write here\n",
        "val_loader = # write here\n",
        "test_loader = # write here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u4ZuIvaTopQ"
      },
      "source": [
        "Let's visualize a batch of data using the make_grid helper function from Torchvision."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWKAkHmwTkAB"
      },
      "source": [
        "for images, _ in train_loader:\n",
        "    print('images.shape:', images.shape)\n",
        "    plt.figure(figsize=(16,8))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(make_grid(images, nrow=16).permute((1, 2, 0)))\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBEn2DmRT116"
      },
      "source": [
        "# Base Model class & Training on GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr113nneT2j-"
      },
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTzgGKKzUSxK"
      },
      "source": [
        "## Training code function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT0dHkQ0UBha"
      },
      "source": [
        "def evaluate(model, val_loader):\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BzfHqyOUcxH"
      },
      "source": [
        ", let's also define some utilities for moving out data & labels to the GPU, if one is available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGpyAs-DUXdn"
      },
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u7KLDhTUgfH"
      },
      "source": [
        "device = get_default_device()\n",
        "device\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lIe8Rj7Ui-A"
      },
      "source": [
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TuPz-MLVWqJ"
      },
      "source": [
        "def plot_losses(history):\n",
        "    losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(losses, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.title('Loss vs. No. of epochs');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX_zhXJDVWtr"
      },
      "source": [
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEbqzIxYVbCM"
      },
      "source": [
        "# moving dataloader to gpu\n",
        "train_loader = DeviceDataLoader(train_loader, device)\n",
        "val_loader = DeviceDataLoader(val_loader, device)\n",
        "test_loader = DeviceDataLoader(test_loader, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDQDRjAfVpsK"
      },
      "source": [
        "Training the model\n",
        "\n",
        "We will make several attempts at training the model. Each time, try a different architecture and a different set of learning rates. Here are some ideas to try:\n",
        "\n",
        "1.    Increase or decrease the number of hidden layers\n",
        "2.    Increase of decrease the size of each hidden layer\n",
        "3.    Try different activation functions\n",
        "4.    Try training for different number of epochs\n",
        "5.    Try different learning rates in every epoch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhttcE01VjOJ"
      },
      "source": [
        "input_size = 3*32*32\n",
        "output_size = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5wnVJN9V8Yg"
      },
      "source": [
        "## Q8: create a model \n",
        "## ImageClassificationBase class to complete the model definition.\n",
        "hint :  Define the __init__ and forward methods.\n",
        "two hidden layer of size 256 and 64"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5FcNpb4V188"
      },
      "source": [
        "class CIFAR10Model(ImageClassificationBase):\n",
        "    def __init__(self, in_size, out_size):\n",
        "        super().__init__()\n",
        "        self.linear1 = # write here)\n",
        "        self.linear2 = # write here\n",
        "        self.linear3 = # write here\n",
        "        \n",
        "        \n",
        "    def forward(self, xb):\n",
        "        # Flatten images into vectors\n",
        "        out = xb.view(xb.size(0), -1)\n",
        "        # Apply layers & activation functions\n",
        "        out = self.linear1(out)\n",
        "        out = F.relu6(out)\n",
        "        out = self.linear2(out)\n",
        "        out = F.relu6(out)\n",
        "        out = self.linear3(out)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7KdGtChWS6I"
      },
      "source": [
        "model = to_device(CIFAR10Model(input_size, output_size), device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AE8c7_D8Wgnq"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV2PpqqAWlWC"
      },
      "source": [
        "ans: \n",
        "\n",
        "```\n",
        "CIFAR10Model(\n",
        "  (linear1): Linear(in_features=3072, out_features=256, bias=True)\n",
        "  (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
        "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
        "# )\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NySkZxtWhtD"
      },
      "source": [
        "history = [evaluate(model, val_loader)]\n",
        "history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDWKQVP7W1KJ"
      },
      "source": [
        "## Q9: Train the model using the fit function to reduce the validation loss & improve accuracy\n",
        "adjusting the no. of epochs & learning rate each time based on the result of the previous training phase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rP1Zjo8Wwoi"
      },
      "source": [
        "history += # write here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKfszx5pXQJQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKTRp5CgXQMr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJNHYMFcXNgt"
      },
      "source": [
        "plot history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GN2kYpFW-hI"
      },
      "source": [
        "plot_losses(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds0jYiNJXRKX"
      },
      "source": [
        "plot_accuracies(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jIBxGuNXbxl"
      },
      "source": [
        "# q10: evaluate the model on the test dataset report its final performance.\n",
        "use evaluate function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_SAfI2BXUAu"
      },
      "source": [
        "a=evaluate(model, test_loader)\n",
        "a\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esnFT_e2Xrtt"
      },
      "source": [
        "save your model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T94rzhyaXh6o"
      },
      "source": [
        "torch.save(model.state_dict(), 'cifar10-feedforward.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMWKcaGiXtQR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}